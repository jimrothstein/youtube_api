---
title: Template for .Rmd
output: 
  pdf_document:
    latex_engine: xelatex
    toc:  TRUE
    toc_depth:  1
fontsize: 12pt
geometry: margin=0.5in,top=0.25in
#  md_document:
#  html_document:
#    toc: true
#  	toc_float: true
#    css: styles.css
---

/home/jim/code/pkg_yt_api/exclude/011_playlists.Rmd

---- PURPOSE ----
given a channel_id , return list of all playlists
----------------
```{r setup, include=FALSE		}
knitr::opts_chunk$set(echo = TRUE,  
											comment="      ##",  
											error=TRUE, 
											collapse=TRUE)
load_all()
```

```{r render, eval=FALSE	}
here()
file <- "011_playlists.Rmd"
file  <- basename(file)
dir="rmd"

```
```{r initialize}
if (!exists("api")) api  <- get_api_codes()
if (!exists("l"))   l    <- get_typical_values()
base_url <- "https://www.googleapis.com/youtube/v3/playlists"
```

Auth_code (should not be NULL)
```{r get_auth_code}
auth.code  <- getOption("auth.code")
auth.code
```

```{r get_count_playlists}

```


TODO - not returning nextPageToken (actually, it is, just toofwe playlists!)
```{r query}
query  <- NULL
query  <- list( 
			part="snippet",
			channelId = l$channelId,
			maxResults = l$maxResults,
      fields=paste(sep=",", 
                   "nextPageToken",
                  "items(id,snippet(title,description,publishedAt))"
                  ),
			key = api$api_key,
			pageToken = NULL)
query

```
```{r HEAD}

r <- httr::HEAD(base_url, 
           query = query,
					 config = httr::config( token = auth.code))
r

```

## HELPER:

More batches?
*  Helper function: 
*  Get next page token
*  Run GET again,  return next r

```{r get_batch}
get_batch  <- function() {
  r <- httr::GET(base_url, 
  query = query,
  config = httr::config(token = auth.code))  %>% 
  httr::stop_for_status()
}
```
From r, process playlists
*  Helper function
*  Process comments into tibblel
*  Rbind with prior batches, return 

```{r process_comments}
process_playlists  <- function(r, playlists = tibble::tibble()) {
  json_content <- get_json(r)
  next_playlists <- cbind(playlistId =json_content$items$id,
                          json_content$items$snippet)
  next_playlists <- tibble::as_tibble(next_playlists)
  playlists <- rbind(playlists, next_playlists)
}
```
***
```{r first_batch }
r  <- get_batch()
playlists  <- process_playlists(r)
playlists

```
```{r}
httr::content(r)$nextPageToken

while ( !is.null(httr::content(r)$nextPageToken )) {
  query$pageToken  <- httr::content(r)$nextPageToken
	r  <- get_batch()
	playlists  <- process_playlists(r, playlists)

} # end loop
playlists
```

### save playlists
```{r}
saveRDS(playlists, file=here("data", "playlists.RDS"))
```

### read playlists
```{r readRDS}
x  <- readRDS(here("data", "playlists.RDS"))
x
```


### pretty the date.  
```{r}
# google stores dates as ISO 8601, as string
# why need TWO lubridate commands to retrieve simple date?
playlists <- playlists %>% 
	dplyr::mutate(date= lubridate::as_date(
									lubridate::as_datetime(publishedAt))) %>% 
	dplyr::select(-c(publishedAt))

playlists
# example playlistId  
playlists$playlistId[[2]]
```

